{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fceb54d8-0982-4942-9a14-5fb132df31dd",
   "metadata": {},
   "source": [
    "'''\n",
    "Notice, some of the files contains a line of\n",
    "    channel_first = (torch.sigmoid((channel_first)) - 0.5) * 7 +0.5\n",
    "The purpose is to visulization the values out of 0 to 1. But this is not the designed way to use the model defined in this proj.\n",
    "When the model outputs black or while image, try this out.\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e97d35-31a5-4973-b688-33397101c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "#print(colored('hello', 'red'), colored('world', 'green'))\n",
    "#print(colored(\"hello red world\", 'red'))\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "from scipy import signal, special\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "#My customized part.\n",
    "import pytorch_yagaodirac as yd\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07d5f94-ae27-4500-baa9-89a058c60ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m-----------------   1   ------------------\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'Indicator0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\YAGAOD~1\\AppData\\Local\\Temp/ipykernel_2504/1827287885.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mF\"-----------------   {data_gen.epoch}   ------------------\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0m_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndicator0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0m_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndicator1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1186\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'Indicator0'"
     ]
    }
   ],
   "source": [
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, output_dims=3):\n",
    "        super().__init__()\n",
    "        # model . Model part must be in front of the optim part, since the init of optimizer relies on the registered layers.\n",
    "        in_dim = 2\n",
    "        out_put = 3\n",
    "        width = 16\n",
    "        units = [in_dim]\n",
    "\n",
    "        self.yd_lin = []\n",
    "\n",
    "        i = 0\n",
    "        units.append(width)\n",
    "        self.Lin0 = yd.nn.Linear(units[i], units[i + 1], bn_cont=False)\n",
    "        self.yd_lin.append(self.Lin0)\n",
    "\n",
    "        i = 1\n",
    "        units.append(width)\n",
    "        self.Lin1 = yd.nn.Linear(units[i], units[i + 1], bn_cont=False)\n",
    "        self.yd_lin.append(self.Lin1)\n",
    "\n",
    "        ################Don't modify anything under this line unless you know what you are doing.\n",
    "        units.append(out_put)\n",
    "        self.Output = torch.nn.Linear(units[-2], units[-1])\n",
    "        self.Output.weight = torch.nn.Parameter(self.Output.weight / units[-2])\n",
    "\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.opt = torch.optim.RMSprop(self.parameters(),\n",
    "                                       lr=1e-2)  # I personally prefer RMSprop, but the original proj used Adam. Probably doesn't affect too much.\n",
    "        self.sdl = yd.optim.AutoScheduler(self.opt, distance=10)\n",
    "        self.printing = False\n",
    "\n",
    "        self.sparser = yd.sparser.Sparser_torch_nn_Linear(abs_dist=0.02, rel_dist=0.1)\n",
    "        self.dropout_small = torch.nn.Dropout(p=0.2)\n",
    "        self.dropout_big = torch.nn.Dropout(p=0.4)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Lin0(x)\n",
    "\n",
    "        x = self.Lin1(x)\n",
    "\n",
    "        # debug_string = \"hidden layer 1:\"\n",
    "        # if self.printing:\n",
    "        #    if len(list(x.shape)) == 1:\n",
    "        #        print(F\"{debug_string}{x}\")\n",
    "        #        pass\n",
    "        #    else:\n",
    "        #        print(F\"{debug_string}{x}\")\n",
    "        #        pass\n",
    "        #    pass\n",
    "        x = self.Output(x)\n",
    "        #x = self.gbnOut(x)\n",
    "        return x\n",
    "        pass  # def forward\n",
    "\n",
    "    def on_batch_begin(self):\n",
    "        self.opt.zero_grad()\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self):\n",
    "        self.opt.step()\n",
    "        pass\n",
    "\n",
    "    def on_opt_stepped(self):\n",
    "        for l in self.yd_lin:\n",
    "            l.on_opt_stepped()\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    pass  # class\n",
    "\n",
    "\n",
    "model = Model().float().cuda()\n",
    "\n",
    "# data_gen = NoPEDateGen('dataset/', 'dot second version.png').cuda()\n",
    "# data_gen = NoPEDateGen('dataset/', 'dot 3.0.png').cuda()\n",
    "# data_gen = yd.datagen.nerf2d_datagen_no_pe('dataset/', 'glasses.jpg').cuda()\n",
    "data_gen = yd.datagen.nerf2d_datagen_no_pe('dataset/', 'compound dot.png').cuda()\n",
    "save_format = 'jpg'\n",
    "save_format = 'png'\n",
    "\n",
    "batch_size = 1024  # 1024\n",
    "########################################################################################################################################################################\n",
    "save_every = 1\n",
    "total_save = 5\n",
    "epochs = save_every * total_save\n",
    "save_counter = yd.Counter(save_every)\n",
    "\n",
    "epochs = 5\n",
    "save_counter = yd.Counter_log(min_step_length=1)\n",
    "########################################################################################################################################################################\n",
    "if 1:\n",
    "    epochs = 4\n",
    "    batch_size = 16  # 1024\n",
    "    save_counter = yd.Counter(1)\n",
    "    pass\n",
    "\n",
    "while data_gen.epoch < epochs:\n",
    "    model.train()\n",
    "    model.printing = False\n",
    "    X, Y = data_gen.get_data(batch_size)  # X is coord(x,y), Y is color(R,G,B)\n",
    "    model.on_batch_begin()  # model.opt.zero_grad()\n",
    "    pred = model(X)\n",
    "    loss = model.loss_fn(pred, Y)\n",
    "    loss.backward()\n",
    "    model.on_batch_end()  # model.opt.step()\n",
    "    model.on_opt_stepped()\n",
    "\n",
    "    # break\n",
    "    # print(data_gen.epoch)\n",
    "    if save_counter.get(data_gen.epoch):\n",
    "        with torch.no_grad():\n",
    "            print(colored(F\"-----------------   {data_gen.epoch}   ------------------\", 'green'))\n",
    "            # print(colored(F\"Lin0[0][:4]-------------------------\", 'yellow'))\n",
    "            # print(model.Lin0.weight.data.clone().detach().cpu().numpy()[0][:4])\n",
    "            # print(model.Lin0.bias.data.clone().detach().cpu().numpy()[0])\n",
    "            # print(colored(F\"Lin1[0][:4]-------------------------\", 'yellow'))\n",
    "            # print(model.Lin1.weight.data.clone().detach().cpu().numpy()[0][:4])\n",
    "            # print(model.Lin1.bias.data.clone().detach().cpu().numpy()[0])\n",
    "            print(colored(F\"Output[0][:4]-------------------------\", 'yellow'))\n",
    "            print(model.Output.weight.data.clone().detach().cpu().numpy()[0][:4])\n",
    "            print(model.Output.bias.data.clone().detach().cpu().numpy()[0])\n",
    "\n",
    "            # model.printing = True\n",
    "            # model(torch.tensor([-1, 0], dtype=torch.float32, device=device))\n",
    "            # model(torch.tensor([0, 0], dtype=torch.float32, device=device))\n",
    "            # model(torch.tensor([0, -1], dtype=torch.float32, device=device))\n",
    "            # model.printing = False\n",
    "            pass\n",
    "        model.sdl.step(loss.item())\n",
    "        last_lr = model.sdl.get_last_lr()[0]\n",
    "        print(F\"last lr = {last_lr}\")\n",
    "        #    last_lr)  ###################################################################################\n",
    "        temp = 0\n",
    "        # temp = temp + model.sparser.apply(model.Lin0)\n",
    "        # temp = temp + model.sparser.apply(model.Lin1)\n",
    "        # temp = temp + model.sparser.apply(model.Lin2)\n",
    "        # temp = temp + model.sparser.apply(model.Lin3)\n",
    "        if temp > 0:\n",
    "            print(colored(F\"sparsed: {temp} -----------\", 'red'))\n",
    "            pass\n",
    "        print(F\"Loss:  {loss.item()}\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # coords_ = data_gen.get_pure_coord(256)\n",
    "\n",
    "            # channel_last = model(coords_['data'])\n",
    "            channel_last = torch.empty(0, 3).cuda()\n",
    "            is_last = False\n",
    "            while not is_last:\n",
    "                coords_ = data_gen.get_pure_coord(256)\n",
    "                channel_last = torch.cat((channel_last, model(coords_['data'])))\n",
    "                # raise(Exception(\"STOP!!!!!!!!\"))\n",
    "                is_last = coords_['is_last']\n",
    "                # print(F\"channel_last length   {channel_last.shape}\")\n",
    "                pass  # while 1\n",
    "            # print(channel_last)\n",
    "            channel_first = torch.cat((channel_last[:, 0].view(1, data_gen.H, data_gen.W),\n",
    "                                       channel_last[:, 1].view(1, data_gen.H, data_gen.W),\n",
    "                                       channel_last[:, 2].view(1, data_gen.H, data_gen.W)  # ,\n",
    "                                       #     torch.ones(1,data_gen.H,data_gen.W)\n",
    "                                       ))\n",
    "            # channel_first = (torch.sigmoid((channel_first)) - 0.5) * 7 +0.5#This line converts the data to false color to show the numbers out of 0 to 1\n",
    "            file_name = F'output/{data_gen.file_name} training_evolution_ {data_gen.epoch:04d} .{save_format}'\n",
    "            save_image(channel_first, file_name)\n",
    "            # save_image(torch.rand(3,50,50), F'11111111.png')\n",
    "            pass  # with\n",
    "        pass  # if\n",
    "    pass  # while\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99577b77-95f4-4ebb-81d4-f7b0718ffa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
