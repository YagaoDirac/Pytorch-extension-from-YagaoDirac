{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fceb54d8-0982-4942-9a14-5fb132df31dd",
   "metadata": {},
   "source": [
    "'''\n",
    "Notice, some of the files contains a line of\n",
    "    channel_first = (torch.sigmoid((channel_first)) - 0.5) * 7 +0.5\n",
    "The purpose is to visulization the values out of 0 to 1. But this is not the designed way to use the model defined in this proj.\n",
    "When the model outputs black or while image, try this out.\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e97d35-31a5-4973-b688-33397101c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "#print(colored('hello', 'red'), colored('world', 'green'))\n",
    "#print(colored(\"hello red world\", 'red'))\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "from scipy import signal, special\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "#My customized part.\n",
    "import pytorch_yagaodirac as yd\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07d5f94-ae27-4500-baa9-89a058c60ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mOutput[0][:4]-------------------------\u001b[0m\n",
      "[ 0.05448487  0.00124425 -0.07721502 -0.01385103]\n",
      "0.21518598\n",
      "last lr = 0.01\n",
      "Loss:  0.3744758367538452\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper___cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\YAGAOD~1\\AppData\\Local\\Temp/ipykernel_9140/1427096016.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[0m_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndicator0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mF\"Lin0 converge score: {_r.score}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter\\Nerf2D\\pytorch_yagaodirac\\indicator.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m#new to save1, save1 to save2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_save1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_save2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mthe_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mthe_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper___cat)"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, output_dims=3):\n",
    "        super().__init__()\n",
    "        # model . Model part must be in front of the optim part, since the init of optimizer relies on the registered layers.\n",
    "        in_dim = 4\n",
    "        out_put = 3\n",
    "        width = 16\n",
    "        units = [in_dim]\n",
    "\n",
    "        init_lr = 1e-2\n",
    "        factor = 1  # this is test only. Set to 1.\n",
    "        scale = 1  # this is test only. Set to 1.\n",
    "\n",
    "        i = 0\n",
    "        units.append(width)\n",
    "        self.Lin0 = torch.nn.Linear(units[i], units[i + 1])\n",
    "        self.gbn0 = yd.nn.GBN(scale=scale, lr=init_lr)\n",
    "        self.Lin0.weight = torch.nn.Parameter(self.Lin0.weight / units[i] * factor)\n",
    "        self.Indicator0 = yd.Linear_indicator(self.Lin0)\n",
    "        # self.Lin0.weight = torch.nn.Parameter(torch.tensor([[1, 0.8]]*units[i+1], dtype = torch.float32))\n",
    "        # self.Lin0.bias = torch.nn.Parameter(torch.full((units[i+1],), 0.666* factor, dtype = torch.float32), requires_grad = True)\n",
    "\n",
    "        i = 1\n",
    "        units.append(width)\n",
    "        self.Lin1 = torch.nn.Linear(units[i], units[i + 1])\n",
    "        self.gbn1 = yd.nn.GBN(scale=scale, lr=init_lr)\n",
    "        self.Lin1.weight = torch.nn.Parameter(self.Lin1.weight / units[i] * factor)\n",
    "        self.Indicator1 = yd.Linear_indicator(self.Lin1)\n",
    "        # self.Lin1.weight = torch.nn.Parameter(torch.full((units[i+1], units[i]), 0.444/units[i], dtype = torch.float32), requires_grad = True)\n",
    "        # self.Lin1.bias = torch.nn.Parameter(torch.full((units[i+1],), 0.444* factor, dtype = torch.float32), requires_grad = True)\n",
    "\n",
    "        # i = 2\n",
    "        # units.append(width)\n",
    "        # self.Lin2 = torch.nn.Linear(units[i], units[i+1])\n",
    "        # i = 3\n",
    "        # units.append(width)\n",
    "        # self.Lin3 = torch.nn.Linear(units[i], units[i+1])\n",
    "\n",
    "        ################Don't modify anything under this line unless you know what you are doing.\n",
    "        units.append(out_put)\n",
    "        self.Output = torch.nn.Linear(units[-2], units[-1])\n",
    "        self.gbnOut = yd.nn.GBN(scale=1e-3, lr=init_lr)  # Don't know why it doesn't work at all.\n",
    "        # self.Output.weight = torch.nn.Parameter(torch.full((units[-1], units[-2]), 0.123/units[-2]* factor, dtype = torch.float32), requires_grad = True)\n",
    "        self.Output.weight = torch.nn.Parameter(self.Output.weight / units[-2] * factor)\n",
    "        # self.Output.bias = torch.nn.Parameter(torch.full((units[-1], ), 0.35* factor, dtype = torch.float32), requires_grad = True)\n",
    "        # self.Output.bias = torch.nn.Parameter(torch.full((units[-1], ), 0.35* factor, dtype = torch.float32), requires_grad = True)\n",
    "\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.opt = torch.optim.RMSprop(self.parameters(),\n",
    "                                       lr=init_lr)  # I personally prefer RMSprop, but the original proj used Adam. Probably doesn't affect too much.\n",
    "        self.sdl = yd.optim.AutoScheduler(self.opt, distance=10)\n",
    "        self.printing = False\n",
    "\n",
    "        self.sparser = yd.sparser.Sparser_torch_nn_Linear(abs_dist=0.02, rel_dist=0.1)\n",
    "        self.dropout_small = torch.nn.Dropout(p=0.2)\n",
    "        self.dropout_big = torch.nn.Dropout(p=0.4)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = x + 2.\n",
    "        h2 = x - 2.\n",
    "        x = torch.cat((h1, h2), dim=-1)\n",
    "\n",
    "        # x = self.dropout_small(x)\n",
    "\n",
    "        x = self.Lin0(x)\n",
    "        x = self.gbn0(x)  ###########\n",
    "        x = yd.Gaussian(x)\n",
    "        # x = torch.sin(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.dropout_big(x)\n",
    "\n",
    "        x = self.Lin1(x)\n",
    "        x = self.gbn1(x)\n",
    "        x = yd.Gaussian(x)\n",
    "        # x = self.dropout_big(x)\n",
    "\n",
    "        # debug_string = \"hidden layer 1:\"\n",
    "        # if self.printing:\n",
    "        #    if len(list(x.shape)) == 1:\n",
    "        #        print(F\"{debug_string}{x}\")\n",
    "        #        pass\n",
    "        #    else:\n",
    "        #        print(F\"{debug_string}{x}\")\n",
    "        #        pass\n",
    "        #    pass\n",
    "        x = self.Output(x)\n",
    "        x = self.gbnOut(x)\n",
    "        return x\n",
    "        pass  # def forward\n",
    "\n",
    "    def on_batch_begin(self):\n",
    "        self.opt.zero_grad()\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self):\n",
    "        self.opt.step()\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def on_checkpoint_begin(self):\n",
    "        pass\n",
    "\n",
    "    def on_checkpoint_end(self):\n",
    "        pass\n",
    "\n",
    "    pass  # class\n",
    "\n",
    "\n",
    "model = Model().float().cuda()\n",
    "\n",
    "# data_gen = NoPEDateGen('dataset/', 'dot second version.png').cuda()\n",
    "# data_gen = NoPEDateGen('dataset/', 'dot 3.0.png').cuda()\n",
    "# data_gen = yd.datagen.nerf2d_datagen_no_pe('dataset/', 'glasses.jpg').cuda()\n",
    "data_gen = yd.datagen.nerf2d_datagen_no_pe('dataset/', 'compound dot.png').cuda()\n",
    "save_format = 'jpg'\n",
    "save_format = 'png'\n",
    "\n",
    "batch_size = 1024  # 1024\n",
    "########################################################################################################################################################################\n",
    "save_every = 1\n",
    "total_save = 5\n",
    "epochs = save_every * total_save\n",
    "save_counter = yd.Counter(save_every)\n",
    "\n",
    "epochs = 20\n",
    "save_counter = yd.Counter_log(min_step_length=10)\n",
    "########################################################################################################################################################################\n",
    "if 0:\n",
    "    epochs = 4\n",
    "    batch_size = 16  # 1024\n",
    "    save_counter = Counter(1)\n",
    "    pass\n",
    "\n",
    "while data_gen.epoch < epochs:\n",
    "    model.train()\n",
    "    model.printing = False\n",
    "    X, Y = data_gen.get_data(batch_size)  # X is coord(x,y), Y is color(R,G,B)\n",
    "    model.on_batch_begin()  # model.opt.zero_grad()\n",
    "    pred = model(X)\n",
    "    loss = model.loss_fn(pred, Y)\n",
    "    loss.backward()\n",
    "    model.on_batch_end()  # model.opt.step()\n",
    "\n",
    "    # break\n",
    "    # print(data_gen.epoch)\n",
    "    if save_counter.get(data_gen.epoch):\n",
    "        with torch.no_grad():\n",
    "            _r = model.Indicator0.update()\n",
    "            if _r.valid:\n",
    "                print(F\"Lin0 converge score: {_r.score}\")\n",
    "                pass\n",
    "            #_r = model.Indicator1.update()\n",
    "            #if _r.valid:\n",
    "            #    print(F\"Lin1 converge score: {_r.score}\")\n",
    "            #    pass\n",
    "            # print(colored(F\"-----------------   {data_gen.epoch}   ------------------\", 'green'))\n",
    "            # print(colored(F\"Lin0[0][:4]-------------------------\", 'yellow'))\n",
    "            # print(model.Lin0.weight.data.clone().detach().cpu().numpy()[0][:4])\n",
    "            # print(model.Lin0.bias.data.clone().detach().cpu().numpy()[0])\n",
    "            # print(colored(F\"Lin1[0][:4]-------------------------\", 'yellow'))\n",
    "            # print(model.Lin1.weight.data.clone().detach().cpu().numpy()[0][:4])\n",
    "            # print(model.Lin1.bias.data.clone().detach().cpu().numpy()[0])\n",
    "            print(colored(F\"Output[0][:4]-------------------------\", 'yellow'))\n",
    "            print(model.Output.weight.data.clone().detach().cpu().numpy()[0][:4])\n",
    "            print(model.Output.bias.data.clone().detach().cpu().numpy()[0])\n",
    "\n",
    "            # model.printing = True\n",
    "            # model(torch.tensor([-1, 0], dtype=torch.float32, device=device))\n",
    "            # model(torch.tensor([0, 0], dtype=torch.float32, device=device))\n",
    "            # model(torch.tensor([0, -1], dtype=torch.float32, device=device))\n",
    "            # model.printing = False\n",
    "            pass\n",
    "        model.sdl.step(loss.item())\n",
    "        last_lr = model.sdl.get_last_lr()[0]\n",
    "        print(F\"last lr = {last_lr}\")\n",
    "        model.gbn0.set_lr(last_lr)  ###################################################################################\n",
    "        model.gbn1.set_lr(last_lr)  ###################################################################################\n",
    "        model.gbnOut.set_lr(\n",
    "            last_lr)  ###################################################################################\n",
    "        temp = 0\n",
    "        # temp = temp + model.sparser.apply(model.Lin0)\n",
    "        # temp = temp + model.sparser.apply(model.Lin1)\n",
    "        # temp = temp + model.sparser.apply(model.Lin2)\n",
    "        # temp = temp + model.sparser.apply(model.Lin3)\n",
    "        if temp > 0:\n",
    "            print(colored(F\"sparsed: {temp} -----------\", 'red'))\n",
    "            pass\n",
    "        print(F\"Loss:  {loss.item()}\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # coords_ = data_gen.get_pure_coord(256)\n",
    "\n",
    "            # channel_last = model(coords_['data'])\n",
    "            channel_last = torch.empty(0, 3).cuda()\n",
    "            is_last = False\n",
    "            while not is_last:\n",
    "                coords_ = data_gen.get_pure_coord(256)\n",
    "                channel_last = torch.cat((channel_last, model(coords_['data'])))\n",
    "                # raise(Exception(\"STOP!!!!!!!!\"))\n",
    "                is_last = coords_['is_last']\n",
    "                # print(F\"channel_last length   {channel_last.shape}\")\n",
    "                pass  # while 1\n",
    "            # print(channel_last)\n",
    "            channel_first = torch.cat((channel_last[:, 0].view(1, data_gen.H, data_gen.W),\n",
    "                                       channel_last[:, 1].view(1, data_gen.H, data_gen.W),\n",
    "                                       channel_last[:, 2].view(1, data_gen.H, data_gen.W)  # ,\n",
    "                                       #     torch.ones(1,data_gen.H,data_gen.W)\n",
    "                                       ))\n",
    "            # channel_first = (torch.sigmoid((channel_first)) - 0.5) * 7 +0.5#This line converts the data to false color to show the numbers out of 0 to 1\n",
    "            file_name = F'output/{data_gen.file_name} training_evolution_ {data_gen.epoch:04d} .{save_format}'\n",
    "            save_image(channel_first, file_name)\n",
    "            # save_image(torch.rand(3,50,50), F'11111111.png')\n",
    "            pass  # with\n",
    "        pass  # if\n",
    "    pass  # while\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99577b77-95f4-4ebb-81d4-f7b0718ffa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
